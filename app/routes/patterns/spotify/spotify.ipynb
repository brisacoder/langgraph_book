{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain-core langchain_openai python-dotenv langsmith pydantic spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet -U jupyterlab-lsp\n",
    "%pip install --quiet -U \"python-lsp-server[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup logging\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Define the format\n",
    "    handlers=[logging.StreamHandler()]  # Output to the console\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Spotify URI type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, NewType\n",
    "\n",
    "# Define a custom URI type\n",
    "SpotifyURI = NewType('SpotifyURI', str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Spotify Track and Playlist Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define a Pydantic model for Playlist\n",
    "class Playlist(BaseModel):\n",
    "    \"\"\"\n",
    "    A model representing a Spotify playlist.\n",
    "    \"\"\"\n",
    "    id: str = Field(..., description=\"The unique identifier for the playlist.\")\n",
    "    uri: str = Field(..., description=\"The Spotify URI for the playlist.\")\n",
    "    name: str = Field(..., description=\"The name of the playlist.\")\n",
    "    description: Optional[str] = Field(None, description=\"The playlist's description.\")\n",
    "    owner: Optional[str] = Field(None, description=\"The display name of the playlist's owner.\")\n",
    "    tracks_total: Optional[int] = Field(None, description=\"The total number of tracks in the playlist.\")\n",
    "    is_public: Optional[bool] = Field(None, description=\"Indicates if the playlist is public.\")\n",
    "    collaborative: Optional[bool] = Field(None, description=\"Indicates if the playlist is collaborative.\")\n",
    "    snapshot_id: Optional[str] = Field(None, description=\"The version identifier for the current playlist.\")\n",
    "\n",
    "# Define a Pydantic model for Track\n",
    "class Track(BaseModel):\n",
    "    \"\"\"\n",
    "    A model representing a Spotify track.\n",
    "    \"\"\"\n",
    "    id: str = Field(..., description=\"The unique identifier for the track.\")\n",
    "    uri: str = Field(..., description=\"The Spotify URI for the track.\")\n",
    "    name: str = Field(..., description=\"The name of the track.\")\n",
    "    artists: List[str] = Field(..., description=\"A list of artists who performed the track.\")\n",
    "    album: str = Field(..., description=\"The name of the album the track is from.\")\n",
    "    duration_ms: Optional[int] = Field(None, description=\"The track length in milliseconds.\")\n",
    "    explicit: Optional[bool] = Field(None, description=\"Indicates if the track has explicit content.\")\n",
    "    popularity: Optional[int] = Field(None, description=\"The popularity of the track (0-100).\")\n",
    "\n",
    "\n",
    "# Define a Pydantic model for Tracks\n",
    "class Tracks(BaseModel):\n",
    "    \"\"\"\n",
    "    A model representing a collection of Spotify tracks.\n",
    "    \"\"\"\n",
    "    tracks: List[Track] = Field(..., description=\"A list of Track objects.\")\n",
    "    total: Optional[int] = Field(None, description=\"Total number of tracks in the collection.\")\n",
    "    playlist_name: Optional[str] = Field(None, description=\"Name of the playlist.\")\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"\n",
    "        Configuration for the Tracks model.\n",
    "        \"\"\"\n",
    "        str_strip_whitespace = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any, Annotated, Set\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict, total=False):\n",
    "    \"\"\"\n",
    "    Represents the state of the conversation and Spotify information\n",
    "\n",
    "    Attributes:\n",
    "        playlists (List[Playlist]): A list of Spotify Playlists.\n",
    "        tracks (List[Track]): Track list for a Spotify Playlist\n",
    "        new_playlist: (Playlist) : New Spotify playlist data\n",
    "        new_tracks: (List[Track]): Tracks for the new playlist\n",
    "    \"\"\"\n",
    "    new_playlist: Playlist\n",
    "    new_tracks: List[Track]\n",
    "    valid_artists: Set[str]\n",
    "    candidate_artists : Set[str]\n",
    "    playlists: List[Playlist]\n",
    "    tracks: List[Track]\n",
    "    artists: Set[str]\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "\n",
    "state: State = State()\n",
    "\n",
    "def get_state():\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Spotify Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from langchain_core.tools import tool\n",
    "from typing import List, NewType, Set\n",
    "import json\n",
    "\n",
    "\n",
    "def get_spotify_client() -> spotipy.Spotify:\n",
    "    \"\"\"\n",
    "    Initializes and returns a Spotify client with user authentication.\n",
    "\n",
    "    Returns:\n",
    "        spotipy.Spotify: An authenticated Spotify client.\n",
    "    \"\"\"\n",
    "    auth_manager = SpotifyClientCredentials(\n",
    "        client_id=os.environ.get(\"SPOTIFY_CLIENT_ID\"),\n",
    "        client_secret=os.environ.get(\"SPOTIFY_CLIENT_SECRET\"),\n",
    "    )\n",
    "    return spotipy.Spotify(auth_manager=auth_manager)\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_playlists() -> Dict[str, List[Playlist]]:\n",
    "    \"\"\"\n",
    "    Retrieves a list of the user's Spotify playlists.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[Playlist]]: A dictionary containing a list of Playlist models under the 'playlists' key.\n",
    "    \"\"\"\n",
    "    sp = get_spotify_client()\n",
    "    playlists: List[Playlist] = []\n",
    "\n",
    "    try:\n",
    "        # Fetch the current user's playlists with pagination\n",
    "        playlists_raw = sp.user_playlists(user=os.getenv(\"SPOTIFY_USER_ID\"), limit=100)\n",
    "        while playlists_raw:\n",
    "            for playlist_data in playlists_raw['items']:\n",
    "                # Map API data to the Playlist model\n",
    "                playlist = Playlist(\n",
    "                    id=playlist_data['id'],\n",
    "                    uri=playlist_data['uri'],\n",
    "                    name=playlist_data['name'],\n",
    "                    description=playlist_data.get('description'),\n",
    "                    owner=playlist_data['owner']['display_name'],\n",
    "                    tracks_total=playlist_data['tracks']['total'],\n",
    "                    is_public=playlist_data.get('public'),\n",
    "                    collaborative=playlist_data.get('collaborative'),\n",
    "                    snapshot_id=playlist_data.get('snapshot_id')\n",
    "                )\n",
    "                playlists.append(playlist)\n",
    "            # Check if there is a next page\n",
    "            if playlists_raw['next']:\n",
    "                playlists_raw = sp.next(playlists_raw)\n",
    "            else:\n",
    "                break\n",
    "    except spotipy.SpotifyException as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "    # Save state\n",
    "    state: State= get_state()\n",
    "    state[\"playlists\"] = playlists\n",
    "\n",
    "    # Serialize the playlists to JSON-serializable dictionaries\n",
    "    serialized_playlists = [playlist.model_dump() for playlist in playlists]\n",
    "    return {\"playlists\": serialized_playlists}\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_track_list(playlist_id: SpotifyURI) -> Dict[str, List[Track]]:\n",
    "    \"\"\"\n",
    "    Retrieves the track list for a specific Spotify playlist.\n",
    "\n",
    "    Args:\n",
    "        playlist_id (SpotifyURI): Spotify playlist URI in the format spotify:playlist:<base-62 number>\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[Track]]: A dictionary containing a list of Track models under the 'tracks' key.\n",
    "    \"\"\"\n",
    "    sp = get_spotify_client()\n",
    "    playlist_tracks: List[Track] = []\n",
    "    playlist_artists: Set[str] = set()\n",
    "\n",
    "    try:\n",
    "        # Fetch the playlist's tracks with pagination\n",
    "        playlist = sp.user_playlist(user=os.getenv(\"SPOTIFY_USER_ID\"), playlist_id=playlist_id)\n",
    "        if 'tracks' in playlist:\n",
    "            tracks = playlist[\"tracks\"]\n",
    "            while tracks:\n",
    "                for item in tracks['items']:\n",
    "                    track_data = item['track']\n",
    "                    # Map API data to the Track model\n",
    "                    track = Track(\n",
    "                        id=track_data['id'],\n",
    "                        uri=track_data['uri'],\n",
    "                        name=track_data['name'],\n",
    "                        artists=[artist['name'] for artist in track_data['artists']],\n",
    "                        album=track_data['album']['name'],\n",
    "                        duration_ms=track_data.get('duration_ms'),\n",
    "                        explicit=track_data.get('explicit'),\n",
    "                        popularity=track_data.get('popularity')\n",
    "                    )\n",
    "                    playlist_tracks.append(track)\n",
    "                    [playlist_artists.add(artist['name']) for artist in track_data['artists']]\n",
    "                # Check if there is a next page\n",
    "                if tracks['next']:\n",
    "                    # TODO unclear in this case\n",
    "                    tracks = sp.next(tracks)\n",
    "                else:\n",
    "                    break\n",
    "    except spotipy.SpotifyException as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "    # Save state\n",
    "    state: State= get_state()\n",
    "    state[\"tracks\"] = playlist_tracks\n",
    "    state[\"artists\"] = playlist_artists\n",
    "\n",
    "    # Serialize the tracks to JSON-serializable dictionaries\n",
    "    serialized_tracks = [track.model_dump() for track in playlist_tracks]\n",
    "    return {\"tracks\": serialized_tracks}\n",
    "\n",
    "\n",
    "@tool\n",
    "def create_spotify_playlist(name: str, description: str = \"Agentic Playlist\") -> Dict[str, Playlist]:\n",
    "    \"\"\"\n",
    "    Creates a new playlist on Spotify.\n",
    "\n",
    "    This function only creates the playlist; it does not add tracks.\n",
    "    See tool add_tracks_to_playlist() to add tracks to a existing playlist\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the new playlist.\n",
    "        description (str, optional): The description of the playlist.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Playlist]: A dictionary containing the new Playlist model under the 'new_playlist' key.\n",
    "    \"\"\"\n",
    "    sp = get_spotify_client()\n",
    "    try:\n",
    "        # Create a new playlist\n",
    "        new_playlist_data = sp.user_playlist_create(\n",
    "            user=os.getenv(\"SPOTIFY_USER_ID\"),\n",
    "            name=name,\n",
    "            public=True,\n",
    "            description=description\n",
    "        )\n",
    "        # Map API data to the Playlist model\n",
    "        new_playlist = Playlist(\n",
    "            id=new_playlist_data['id'],\n",
    "            uri=new_playlist_data['uri'],\n",
    "            name=new_playlist_data['name'],\n",
    "            description=new_playlist_data.get('description'),\n",
    "            owner=new_playlist_data['owner']['display_name'],\n",
    "            tracks_total=new_playlist_data['tracks']['total'],\n",
    "            is_public=new_playlist_data.get('public'),\n",
    "            collaborative=new_playlist_data.get('collaborative'),\n",
    "            snapshot_id=new_playlist_data.get('snapshot_id')\n",
    "        )\n",
    "        state: State = get_state()\n",
    "        state[\"new_playlist\"] = new_playlist\n",
    "    except spotipy.SpotifyException as e:\n",
    "        return {\"error\": str(e)}\n",
    "    return {\"new_playlist\": new_playlist.model_dump()}\n",
    "\n",
    "@tool\n",
    "def add_tracks_to_playlist(playlist_id: str, tracks: Tracks) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Adds tracks to a Spotify playlist.\n",
    "\n",
    "    Args:\n",
    "        playlist_id (str): ID of the playlist.\n",
    "        tracks (Tracks): Spotify Pydantic Model of a List of tracks\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: A dictionary indicating success or error.\n",
    "    \"\"\"\n",
    "    sp = get_spotify_client()\n",
    "    try:\n",
    "        sp.playlist_add_items(playlist_id=playlist_id, items=tracks)\n",
    "    except spotipy.SpotifyException as e:\n",
    "        return {\"error\": str(e)}\n",
    "    return {\"success\": True} \n",
    "\n",
    "@tool\n",
    "def check_artists(playlist_id: str, artists: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Check a list of artists for a new Playlist against a existing Playlist\n",
    "\n",
    "    Args:\n",
    "        playlist_id (SpotifyURI): Spotify playlist URI in the format spotify:playlist:<base-62 number>\n",
    "        artists (str): A list of new artist names\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Set[str]]: Dict with a Set of artists that can be used in the new playlist\n",
    "    \"\"\"\n",
    "    state: State = get_state()\n",
    "    state['candidate_artists'] = set(artists)\n",
    "    valid_artists = state['candidate_artists'] - state[\"artists\"]\n",
    "    state[\"valid_artists\"] = valid_artists\n",
    "    return {\"valid_artists\": valid_artists}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search_tool = TavilySearchResults(\n",
    "    max_results=50,\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    include_images=True,\n",
    "    # search_depth=\"advanced\",\n",
    "    # include_domains = []\n",
    "    # exclude_domains = []\n",
    ")\n",
    "name = search_tool.get_name()\n",
    "desc = search_tool.description\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Plan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step(BaseModel):\n",
    "    \"\"\"\n",
    "    The `Step` class represents an atomic unit of work within a plan. Each task must be focused on a single, clear objective and should not encompass multiple, unrelated activities.\n",
    "\n",
    "    Key Points:\n",
    "    - A task should perform one specific function and should not combine different activities. \n",
    "    - Each task should have a clear, verifiable success criterion that is achievable through the task's activities alone.\n",
    "    - Steps must be URL-friendly, without spaces or special characters in their names.\n",
    "    \n",
    "    **Examples of What a Task Should NOT Do:**\n",
    "    - \"Create a playlist and add tracks\" (This task mixes playlist creation with track management.)\n",
    "    - \"Search new artists and apply filtering.\" (This task combines artist search with its management, which should be separated.)\n",
    "    - \"Collect all relevant information about the playlist Spotify and User\" (This task has two action items)\n",
    "\n",
    "    Attributes:\n",
    "    - `name` (str): URL-friendly name for the task, e.g., 'deploy-application'. Must not contain spaces or special characters.\n",
    "    - `description` (str): A detailed description of the task, e.g., 'Deploy the application to the Kubernetes cluster using Helm.'\n",
    "    - `success_criteria` (str): Clear and verifiable criteria for task completion, e.g., 'Application is successfully deployed and running in the Kubernetes cluster, as verified by checking the deployment status with 'kubectl get deployments'.' Each task must be atomic and focus on one thing only.\n",
    "    - `tools` (List[str]): List of `Tool Calling` instances required for the task, specifying which tools are needed.\n",
    "\n",
    "    \"\"\"    \n",
    "    name: str = Field(..., description=\"URL-friendly name for the task, e.g., 'deploy-application'. Must not contain spaces or special characters.\")\n",
    "    description: str = Field(..., description=\"A detailed description of the task, e.g., 'Deploy the application to the Kubernetes cluster using Helm.'\")\n",
    "    success_criteria: str = Field(..., description=\"Clear and verifiable criteria for task completion, e.g., 'Application is successfully deployed and running in the Kubernetes cluster, as verified by checking the deployment status with 'kubectl get deployments'.' Each task must be atomic and focus on one thing only.\")\n",
    "    tools: List[str] = Field(..., description=\"List of `Tool` instances required for the task, specifying which tools are needed.\")\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for the Task model.\"\"\"\n",
    "        json_schema_extra = {\n",
    "            \"description\": \"The `Task` class represents an atomic unit of work that involves using specific tools to achieve a clear goal.\"\n",
    "            # Removed 'examples' as it is now handled at the field level\n",
    "        }\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    steps: List[Step] = Field(\n",
    "        ..., \n",
    "        description=(\n",
    "            \"A list of `Steps` that constitute the plan. Each step must be atomic, \"\n",
    "            \"focused on a specific goal, and the entire plan must be complete, verifiable, \"\n",
    "            \"and reproducible.\"\n",
    "        )\n",
    "    )\n",
    "    Reasoning: str = Field(\n",
    "        ..., \n",
    "        description=(\n",
    "            \"OpenAI should capture here the entire reasoning sequence used to create \"\n",
    "            \" the plan\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def validate_plan(plan: Plan) -> bool:\n",
    "    \"\"\"\n",
    "    Validates a step-by-step plan to solve a problem\n",
    "\n",
    "    Args:\n",
    "        plan (Plan): a step-by-step plan to solve a problem\n",
    "\n",
    "    Returns:\n",
    "        bool: whether plan is okay or not\n",
    "    \"\"\"\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools = [get_playlists, get_track_list, create_spotify_playlist, add_tracks_to_playlist, check_artists, validate_plan, search_tool]\n",
    "# tools = [get_playlists, get_track_list, create_spotify_playlist, add_tracks_to_playlist, search_tool]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Test of Tool Infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "message_with_single_tool_call = AIMessage(\n",
    "    content=\"\",\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"name\": \"get_playlists\",\n",
    "            \"args\" : {},\n",
    "            \"id\": \"tool_call_id\",\n",
    "            \"type\": \"tool_call\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# tool_node.invoke({\"messages\": [message_with_single_tool_call]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bind Tools to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=os.getenv(\"OPENAI_MODEL_NAME\"), temperature=0.8)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Create and execute a step-by-step plan with atomic tasks to solve the following problem:\n",
    "\n",
    "**Objective:** Build a Spotify playlist with tracks that have the same vibe and genres as my 'New Rock and Blues' playlist, following the rules below.\n",
    "\n",
    "**Rules:**\n",
    "\n",
    "1. **For each artist in the 'New Rock and Blues' playlist, find 3-4 artists of the similar music style**\n",
    "\n",
    "2 .**Exclude Artists that are part of the  'New Rock and Blues' Playlist:**\n",
    "\n",
    "3. **Focus on Post-2010 Success:** Only include tracks from artists who achieved success after the year 2010.\n",
    "\n",
    "4. **Minimum Number of New Artists:** Include tracks from at least 40 different artists not present in the 'New Rock and Blues' playlist.\n",
    "\n",
    "5. **For each new artist, use your Knowledge Base to recommend 3-4 tracks that match the vibe and genres.\n",
    "\n",
    "6. **Arrange for Smooth Listening Experience:** Organize the tracks to create a smooth listening experience, considering tempo, energy, and mood, using best practices.\n",
    "\n",
    "7. **Playlist Length:** Ensure the new playlist contains at least 100 tracks.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Follow the rules strictly to meet the objective.\n",
    "- Every step must have a single atomic action and outcome\n",
    "- Prefer using a tool if available instead of your Knowledge Base\n",
    "- clearly state at all times what step you are working on\n",
    "- Step(s) should be repeated any number of times to achieve the desired outcome.\n",
    "- Do not ask for user confirmation\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "human_message = HumanMessage(prompt)\n",
    "ai_tool_call_message = llm_with_tools.invoke([human_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_tool_call_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chat_prompt_template holds all messages (Human, AI, Tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt_template: ChatPromptTemplate = human_message + ai_tool_call_message\n",
    "chat_prompt_template.format_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Tools in Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "tools_in_ai_message = []\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "messages = chat_prompt_template.format_messages()\n",
    "for tool_call in messages[-1].tool_calls:\n",
    "    tool = tools_by_name[tool_call[\"name\"]]\n",
    "    tools_in_ai_message.append(tool)\n",
    "    # observation = tool.invoke(tool_call[\"args\"])\n",
    "    # result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "if len(tools_in_ai_message) == 0 or len(tools_in_ai_message) > 1:\n",
    "    raise ValueError\n",
    "else:\n",
    "    print(tools_in_ai_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call (should be validate_plan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = chat_prompt_template.format_messages()\n",
    "response = tool_node.invoke({\"messages\": messages})\n",
    "tool_message = response[\"messages\"][0]\n",
    "tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += tool_message\n",
    "chat_prompt_template.format_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send tool result to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_tool_call_message = llm_with_tools.invoke(chat_prompt_template.format_messages())\n",
    "ai_tool_call_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call (should be get_playlists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += ai_tool_call_message\n",
    "messages = chat_prompt_template.format_messages()\n",
    "response = tool_node.invoke({\"messages\": messages})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_tool_message: ToolMessage = response[\"messages\"][0]\n",
    "playlist_tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to check that is JSON serializable\n",
    "# json.loads(playlist_tool_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Message List for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += playlist_tool_message\n",
    "chat_prompt_template.format_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Playlists Results to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_tool_call_message = llm_with_tools.invoke(chat_prompt_template.format_messages())\n",
    "ai_tool_call_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += ai_tool_call_message\n",
    "messages = chat_prompt_template.format_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call (get_track_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tool_node.invoke({\"messages\": messages})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode AI Tool Call message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_list_tool_message: ToolMessage = response[\"messages\"][0]\n",
    "track_list_tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.loads(track_list_tool_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Track List ToolMessage for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We recreate the ToolMessage to take care of UNicode characters\n",
    "tool_message = ToolMessage(content=track_list_tool_message.content, name=track_list_tool_message.name, tool_call_id=track_list_tool_message.tool_call_id)\n",
    "tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Tool message containing playlist tracks to list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += tool_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template.format_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Tool Result to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_with_structured_output = llm.with_structured_output(schema=Tracks, method='function_calling', include_raw=True)\n",
    "# response = llm_with_structured_output.invoke(chat_prompt_template.format_messages())\n",
    "# response\n",
    "response = llm_with_tools.invoke(chat_prompt_template.format_messages())\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += response\n",
    "chat_prompt_template.format_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call (check_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tool_node.invoke({\"messages\": [response]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_artist_tool_message: ToolMessage = response[\"messages\"][0]\n",
    "check_artist_tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We recreate the ToolMessage to take care of UNicode characters\n",
    "tool_message = ToolMessage(content=check_artist_tool_message.content, name=check_artist_tool_message.name, tool_call_id=check_artist_tool_message.tool_call_id)\n",
    "tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += tool_message\n",
    "chat_prompt_template.format_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_with_tools.invoke(chat_prompt_template.format_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += response\n",
    "chat_prompt_template.format_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tool_node.invoke({\"messages\": [response]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
