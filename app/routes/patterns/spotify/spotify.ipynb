{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain-core langchain_openai python-dotenv langsmith pydantic spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet -U jupyterlab-lsp\n",
    "%pip install --quiet -U \"python-lsp-server[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup logging\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Define the format\n",
    "    handlers=[logging.StreamHandler()]  # Output to the console\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search_tool = TavilySearchResults(\n",
    "    max_results=50,\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    include_images=True,\n",
    "    # search_depth=\"advanced\",\n",
    "    # include_domains = []\n",
    "    # exclude_domains = []\n",
    ")\n",
    "name = search_tool.get_name()\n",
    "desc = search_tool.description\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from spotify_tools import get_playlists, create_spotify_playlist, add_tracks_to_playlist, filter_artists, get_artists_from_playlist, find_similar_artists, find_top_tracks, get_audio_features\n",
    "from plan import validate_plan\n",
    "\n",
    "tools = [get_playlists, create_spotify_playlist, add_tracks_to_playlist, filter_artists, validate_plan, get_artists_from_playlist, find_similar_artists, find_top_tracks, search_tool, get_audio_features]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bind Tools to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=os.getenv(\"OPENAI_MODEL_NAME\"), temperature=1.0)\n",
    "# llm_with_tools = llm.bind_tools(tools, strict=True, parallel_tool_calls=False)\n",
    "llm_with_tools = llm.bind_tools(tools, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from prompts import Prompts\n",
    "\n",
    "system_message = SystemMessage(Prompts.SYSTEM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from prompts import Prompts\n",
    "\n",
    "human_message = HumanMessage(Prompts.SPOTIFY)\n",
    "llm_response = llm_with_tools.invoke([system_message, human_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if llm_response.tool_calls is None or llm_response.tool_calls[0][\"name\"] != \"validate_plan\":\n",
    "    raise ValueError(\"should be tool message calling 'validate_plan'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = llm_response.tool_calls[0][\"args\"]\n",
    "plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chat_prompt_template holds all messages (Human, AI, Tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt_template: ChatPromptTemplate = system_message + human_message + llm_response\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Tools in Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, List\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "def check_tool_in_messages(messages: List[BaseMessage], tools: List[Callable[..., Any]]) -> List[str]:\n",
    "    tools_in_ai_message = []\n",
    "    tools_by_name = {tool.name: tool for tool in tools}\n",
    "    for tool_call in messages[-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        tools_in_ai_message.append(tool)\n",
    "        # observation = tool.invoke(tool_call[\"args\"])\n",
    "        # result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return tools_in_ai_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call (should be validate_plan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_response = tool_node.invoke({\"messages\": messages})\n",
    "tool_message = tool_response[\"messages\"][0]\n",
    "tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Tool Response to Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += tool_message\n",
    "chat_prompt_template.format_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Messages with Tool result to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = llm_with_tools.invoke(chat_prompt_template.format_messages())\n",
    "llm_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate correct tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if llm_response.tool_calls is None or llm_response.tool_calls[0][\"name\"] != \"get_playlists\":\n",
    "    raise ValueError(\"should be tool message calling 'validate_plan'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call (should be get_playlists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += llm_response\n",
    "messages = chat_prompt_template.format_messages()\n",
    "tool_response = tool_node.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_message in tool_response[\"messages\"]:\n",
    "    tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Tool Response to Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += tool_response[\"messages\"]\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Tool Result Results to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = llm_with_tools.invoke(messages)\n",
    "llm_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate correct tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if llm_response.tool_calls is None or llm_response.tool_calls[0][\"name\"] != \"get_artists_from_playlist\":\n",
    "    raise ValueError(\"should be tool message calling 'get_artists_from_playlist'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add AI Tool Call to Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += llm_response\n",
    "messages = chat_prompt_template.format_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call (get_artists_from_playlist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_response = tool_node.invoke({\"messages\": messages})\n",
    "for tool_message in tool_response[\"messages\"]:\n",
    "    tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Tool Response to Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += tool_response[\"messages\"]\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Tool Result to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = llm_with_tools.invoke(messages)\n",
    "llm_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Tool Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if llm_response.tool_calls is None or llm_response.tool_calls[0][\"name\"] != \"find_similar_artists\":\n",
    "    raise ValueError(\"should be tool message calling 'find_similar_artists'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add AI Tool Call to Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += llm_response\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call (find_similar_artists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_response = tool_node.invoke({\"messages\": messages})\n",
    "for tool_message in  tool_response[\"messages\"]:\n",
    "    tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Tool Response to Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += tool_response[\"messages\"]\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Tool Result to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = llm_with_tools.invoke(messages)\n",
    "llm_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add AI Tool Call to Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += llm_response\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call (filter_artists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_response = tool_node.invoke({\"messages\": messages})\n",
    "for tool_message in  tool_response[\"messages\"]:\n",
    "    tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Tool Response to Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += tool_response[\"messages\"]\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Tool Result to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = llm_with_tools.invoke(messages)\n",
    "llm_response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += llm_response\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if llm_response.tool_calls is None or llm_response.tool_calls[0][\"name\"] != \"filter_artists\":\n",
    "    raise ValueError(\"should be tool message calling 'filter_artists'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_response = tool_node.invoke({\"messages\": messages})\n",
    "for tool_message in  tool_response[\"messages\"]:\n",
    "    tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += tool_response[\"messages\"]\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Tool Result to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = llm_with_tools.invoke(messages)\n",
    "llm_response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += llm_response\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if llm_response.tool_calls is None or llm_response.tool_calls[0][\"name\"] != \"find_top_tracks\":\n",
    "    raise ValueError(\"should be tool message calling 'find_top_tracks'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_response = tool_node.invoke({\"messages\": messages})\n",
    "for tool_message in  tool_response[\"messages\"]:\n",
    "    tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += tool_response[\"messages\"]\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Tool Result to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = llm_with_tools.invoke(messages)\n",
    "llm_response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += llm_response\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_response = tool_node.invoke({\"messages\": messages})\n",
    "for tool_message in  tool_response[\"messages\"]:\n",
    "    tool_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template += tool_response[\"messages\"]\n",
    "messages = chat_prompt_template.format_messages()\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Tool Result to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = llm_with_tools.invoke(messages)\n",
    "llm_response.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
